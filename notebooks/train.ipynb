{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-04 01:32:37.035978: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "cannot find .env file\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(1, \"../scripts\")\n",
    "from config import config\n",
    "import gif_utils\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import model_selection\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import tf2onnx\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "import boto3\n",
    "from pprint import pprint\n",
    "\n",
    "print(tf.config.list_physical_devices(\"GPU\"))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download GIFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def search_giphy(query, limit, offset):\n",
    "#     request_url = (\n",
    "#         f\"https://api.giphy.com/v1/gifs/search?api_key={os.getenv('GIPHY_API_KEY')}\"\n",
    "#         f\"&q={query}&limit={limit}&offset={offset}\"\n",
    "#         f\"&rating=g&lang=en&bundle=messaging_non_clips\"\n",
    "#     )\n",
    "#     response = requests.get(request_url)\n",
    "#     output = json.loads(response.text)\n",
    "#     return output\n",
    "\n",
    "# for label, title in enumerate(config()[\"tv_titles\"]):\n",
    "#     output = search_giphy(title, 50, 0)\n",
    "#     title = title.replace(\" \", \"\")\n",
    "#     for gif in output[\"data\"]:\n",
    "#         id = gif[\"id\"]\n",
    "#         url = gif[\"images\"][\"original\"][\"url\"]\n",
    "#         file_name = f\"{label}_{title}_{id}.gif\"\n",
    "#         file_path = f\"{config()['data_path']}/{file_name}\"\n",
    "#         gif_utils.save_gif(file_path, url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/0_GameofThrones_3o7abLOPn5UJ048sSY.gif'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m gif_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_path\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_gif_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m frames \u001b[38;5;241m=\u001b[39m \u001b[43mgif_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mframes_from_gif\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgif_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(frames\u001b[38;5;241m.\u001b[39mshape, frames\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(frames[\u001b[38;5;241m9\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m))\n",
      "File \u001b[0;32m~/projects/python-projects/gif_analyzer/notebooks/../scripts/gif_utils.py:14\u001b[0m, in \u001b[0;36mframes_from_gif\u001b[0;34m(full_path, n_frames, output_size)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mframes_from_gif\u001b[39m(full_path, n_frames\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, output_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m)):\n\u001b[0;32m---> 14\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_path\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m gif:\n\u001b[1;32m     15\u001b[0m         frame_count \u001b[38;5;241m=\u001b[39m gif\u001b[38;5;241m.\u001b[39mn_frames\n\u001b[1;32m     16\u001b[0m         frame_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mint\u001b[39m(frame_count \u001b[38;5;241m/\u001b[39m n_frames))\n",
      "File \u001b[0;32m~/micromamba/envs/gif_analyzer/lib/python3.10/site-packages/PIL/Image.py:3247\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3244\u001b[0m     filename \u001b[38;5;241m=\u001b[39m fp\n\u001b[1;32m   3246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[0;32m-> 3247\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3248\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   3250\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/0_GameofThrones_3o7abLOPn5UJ048sSY.gif'"
     ]
    }
   ],
   "source": [
    "gif_path = f\"{config()['data_path']}/{config()['test_gif_name']}\"\n",
    "frames = gif_utils.frames_from_gif(gif_path)\n",
    "print(frames.shape, frames.dtype)\n",
    "plt.imshow(frames[9].astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    20\n",
       "6    20\n",
       "8    20\n",
       "1    20\n",
       "0    20\n",
       "2    20\n",
       "9    20\n",
       "3    20\n",
       "7    20\n",
       "4    20\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = os.listdir(config()[\"data_path\"])\n",
    "labels = [file.split(\"_\")[0] for file in files]\n",
    "files_train, files_temp = model_selection.train_test_split(files, test_size=0.4, stratify=labels, random_state=0)\n",
    "labels_temp = [file.split(\"_\")[0] for file in files_temp]\n",
    "files_val, files_test = model_selection.train_test_split(files_temp, test_size=0.5, stratify=labels_temp, random_state=0)\n",
    "pd.Series(labels_temp).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-06 19:04:02.749284: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-06 19:04:02.749489: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-06 19:04:02.749545: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-06 19:04:03.576044: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-06 19:04:03.576136: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-06 19:04:03.576147: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-12-06 19:04:03.576203: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-06 19:04:03.576224: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1416 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "def generator(files):\n",
    "    for file in files:\n",
    "        file = str(file, \"utf-8\")\n",
    "        frames = gif_utils.frames_from_gif(f\"{config()['data_path']}/{file}\")\n",
    "        label = int(file.split(\"_\")[0])\n",
    "        yield frames, label\n",
    "output_signature = (\n",
    "    tf.TensorSpec(shape=(10, 224, 224, 3), dtype=tf.float32),\n",
    "    tf.TensorSpec(shape=(), dtype=tf.int16)\n",
    ")\n",
    "ds_train = tf.data.Dataset.from_generator(generator, args=[files_train], output_signature=output_signature)\n",
    "ds_val = tf.data.Dataset.from_generator(generator, args=[files_val], output_signature=output_signature)\n",
    "ds_test = tf.data.Dataset.from_generator(generator, args=[files_test], output_signature=output_signature)\n",
    "ds_train = ds_train.cache().prefetch(buffer_size=tf.data.AUTOTUNE).batch(2)\n",
    "ds_val = ds_val.cache().prefetch(buffer_size=tf.data.AUTOTUNE).batch(2)\n",
    "ds_test = ds_test.cache().prefetch(buffer_size=tf.data.AUTOTUNE).batch(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.keras.utils.set_random_seed(0)\n",
    "\n",
    "net = tf.keras.applications.efficientnet_v2.EfficientNetV2B0(include_top=False)\n",
    "# net = tf.keras.applications.EfficientNetB0(include_top=False)\n",
    "# net = tf.keras.applications.EfficientNetB5(include_top=False)\n",
    "# net = tf.keras.applications.efficientnet_v2.EfficientNetV2L(include_top=False)\n",
    "net.trainable = False\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.TimeDistributed(net),\n",
    "    tf.keras.layers.Dense(config()[\"num_classes\"]),\n",
    "    tf.keras.layers.GlobalAveragePooling3D()\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(ds_train,\n",
    "          epochs=10,\n",
    "          validation_data=ds_val,\n",
    "          callbacks=tf.keras.callbacks.EarlyStopping(patience=2, monitor=\"val_loss\"))\n",
    "\n",
    "model.summary()\n",
    "model_path = f\"{config()['models_path']}/{config()['model_name']}.keras\"\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from official.projects.movinet.modeling import movinet\n",
    "# from official.projects.movinet.modeling import movinet_model\n",
    "\n",
    "# model_id = \"a0\"\n",
    "# resolution = 224\n",
    "\n",
    "# tf.keras.backend.clear_session()\n",
    "\n",
    "# backbone = movinet.Movinet(model_id=model_id)\n",
    "# backbone.trainable = False\n",
    "\n",
    "# # Set num_classes=600 to load the pre-trained weights from the original model\n",
    "# model = movinet_model.MovinetClassifier(backbone=backbone, num_classes=600)\n",
    "# model.build([None, None, None, None, 3])\n",
    "\n",
    "# checkpoint_dir = f\"movinet_{model_id}_base\"\n",
    "# checkpoint_path = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "# checkpoint = tf.train.Checkpoint(model=model)\n",
    "# status = checkpoint.restore(checkpoint_path)\n",
    "# status.assert_existing_objects_matched()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_classifier(batch_size, num_frames, resolution, backbone, num_classes):\n",
    "#   '''Builds a classifier on top of a backbone model.'''\n",
    "#   model = movinet_model.MovinetClassifier(\n",
    "#       backbone=backbone,\n",
    "#       num_classes=num_classes)\n",
    "#   model.build([batch_size, num_frames, resolution, resolution, 3])\n",
    "\n",
    "#   return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = build_classifier(2, 10, resolution, backbone, 10)\n",
    "\n",
    "# model.compile(\n",
    "#     optimizer=tf.keras.optimizers.Adam(learning_rate = 0.001),\n",
    "#     loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "#     metrics=[\"accuracy\"]\n",
    "# )\n",
    "\n",
    "# model.fit(\n",
    "#     ds_train,\n",
    "#     validation_data=ds_val,\n",
    "#     epochs=2,\n",
    "#     validation_freq=1,\n",
    "#     verbose=1\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model_path = f\"{config()['models_path']}/{config()['model_name']}.keras\"\n",
    "onnx_model_path = f\"{config()['models_path']}/{config()['model_name']}.onnx\"\n",
    "keras_model = keras.models.load_model(keras_model_path)\n",
    "# model_proto, _ = tf2onnx.convert.from_keras(keras_model, output_path=onnx_model_path)\n",
    "# output_names = [n.name for n in model_proto.graph.output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = ort.InferenceSession(onnx_model_path)\n",
    "gif_path = f\"{config()['data_path']}/{config()['test_gif_name']}\"\n",
    "input = gif_utils.frames_from_gif(gif_path)\n",
    "input = np.expand_dims(input, axis=0)\n",
    "keras_pred = keras_model.predict(input)\n",
    "onnx_pred = session.run(None, {\"time_distributed_input\": input})\n",
    "\n",
    "print(\"Keras predicted\", keras_pred)\n",
    "print(\"ONNX predicted:\", onnx_pred[0])\n",
    "\n",
    "# Make sure ONNX and Keras have the same results\n",
    "np.testing.assert_allclose(keras_pred, onnx_pred[0], rtol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/83f5f337909f41988c4dca5b2b12b3d0', creation_time=1701014473840, experiment_id='0', last_update_time=1701097438947, lifecycle_stage='active', name='default', tags={}>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(config()[\"mlflow_tracking_uri\"])\n",
    "mlflow.set_experiment(config()[\"mlflow_experiment_name\"])\n",
    "# with mlflow.start_run():\n",
    "#     signature = infer_signature(input, np.array(onnx_pred))\n",
    "#     onnx_model = onnx.load_model(onnx_model_path)\n",
    "#     mlflow.onnx.log_model(\n",
    "#         onnx_model,\n",
    "#         artifact_path=\"onnx_model\",\n",
    "#         registered_model_name=config()[\"model_name\"],\n",
    "#         signature=signature\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'aliases': [],\n",
      "    'creation_timestamp': 1701855047721,\n",
      "    'current_stage': 'None',\n",
      "    'description': '',\n",
      "    'last_updated_timestamp': 1701859058908,\n",
      "    'name': 'baseline',\n",
      "    'run_id': '2bd605a2a0f94a44b0e3bc22737e77fb',\n",
      "    'run_link': '',\n",
      "    'source': 'runs:/2bd605a2a0f94a44b0e3bc22737e77fb/onnx_model',\n",
      "    'status': 'READY',\n",
      "    'status_message': '',\n",
      "    'tags': {},\n",
      "    'user_id': '',\n",
      "    'version': '2'}\n",
      "{   'aliases': [],\n",
      "    'creation_timestamp': 1701097875853,\n",
      "    'current_stage': 'None',\n",
      "    'description': '',\n",
      "    'last_updated_timestamp': 1701097875853,\n",
      "    'name': 'baseline',\n",
      "    'run_id': '7a45d101dde04f59b34cadc0effdbd64',\n",
      "    'run_link': '',\n",
      "    'source': 'mlflow-artifacts:/83f5f337909f41988c4dca5b2b12b3d0/7a45d101dde04f59b34cadc0effdbd64/artifacts/onnx_model',\n",
      "    'status': 'READY',\n",
      "    'status_message': '',\n",
      "    'tags': {},\n",
      "    'user_id': '',\n",
      "    'version': '1'}\n"
     ]
    }
   ],
   "source": [
    "mlflow_client = mlflow.MlflowClient()\n",
    "models = mlflow_client.search_model_versions()\n",
    "# models = mlflow_client.search_registered_models()\n",
    "for x in models:\n",
    "    pprint(dict(x), indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow_client.set_registered_model_alias(config()[\"model_name\"], \"champion\", \"1\")\n",
    "mlflow_client.set_registered_model_alias(config()[\"model_name\"], \"challenger\", \"2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow_client.delete_registered_model_alias(config()[\"model_name\"], \"challenger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "champion_model = mlflow_client.get_model_version_by_alias('baseline', 'champion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'baseline'\n",
    "alias = 'champion'\n",
    "model = mlflow.onnx.load_model(f'models:/{model_name}@{alias}')\n",
    "onnx.save_model(model, f'../layers/models/{model_name}_{alias}.onnx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actual_predicted_labels(dataset): \n",
    "    actual = [labels for _, labels in dataset.unbatch()]\n",
    "    predicted = model.predict(dataset)\n",
    "\n",
    "    actual = tf.stack(actual, axis=0)\n",
    "    predicted = tf.concat(predicted, axis=0)\n",
    "    predicted = tf.argmax(predicted, axis=1)\n",
    "\n",
    "    return actual, predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(actual, predicted, labels):\n",
    "    cm = tf.math.confusion_matrix(actual, predicted)\n",
    "    ax = sns.heatmap(cm, annot=True, fmt=\"g\")\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"Actual\")\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.yticks(rotation=0)\n",
    "    ax.xaxis.set_ticklabels(labels)\n",
    "    ax.yaxis.set_ticklabels(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = range(config()[\"num_classes\"])\n",
    "actual, predicted = get_actual_predicted_labels(ds_test)\n",
    "plot_confusion_matrix(actual, predicted, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gif_path = f\"{config()['data_path']}/{config()['test_gif_name']}\"\n",
    "sample = gif_utils.frames_from_gif(gif_path)\n",
    "sample = np.expand_dims(sample, axis=0)\n",
    "print(gif_path)\n",
    "with tf.device(\"/CPU:0\"):\n",
    "    prediction = model.predict(sample)\n",
    "    print(prediction)\n",
    "    print(tf.argmax(prediction[0]).numpy())\n",
    "plt.imshow(sample[0][0].astype(\"int\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
